{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47139596-c31c-43c4-941f-f869ab314614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import os, sys, copy, time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import cv2\n",
    "import skimage.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchaudio.transforms as AT\n",
    "from torch.utils.data import  Dataset, TensorDataset, DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from IPython.display import HTML\n",
    "from IPython import display\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(3)\n",
    "np.random.seed(3)\n",
    "torch.manual_seed(3)\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250f620b-e62a-4dbe-89cc-21702ea5637e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "if (device.type == 'cuda') and (torch.cuda.device_count() >1):\n",
    "    print(\"Multi GPU activate\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ccedbf-dea9-4d40-ae2a-5d5db1ec4543",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4e899ec-c099-42ee-b3b2-c7cb5cf499bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Dataset1\"\n",
    "dataset_dir = f\"./{dataset_name}\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "print_every = 1\n",
    "window = 20\n",
    "step_size = 10\n",
    "window_type = 'avg'\n",
    "emb_size = 512\n",
    "d_model = 512\n",
    "max_len = 2000\n",
    "\n",
    "patience = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7869909-ee8b-4dbf-8c3f-6ba7e2a6daf1",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "035e5eae-ca22-4521-b436-cffe5491c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948, 47) (948, 2) (55, 47) (55, 2)\n"
     ]
    }
   ],
   "source": [
    "x_data_OK = np.load(os.path.join(dataset_dir, 'x_data_OK.npy'))\n",
    "y_data_OK = np.load(os.path.join(dataset_dir, 'y_data_OK.npy'))\n",
    "x_data_NG = np.load(os.path.join(dataset_dir, 'x_data_NG.npy'))\n",
    "y_data_NG = np.load(os.path.join(dataset_dir, 'y_data_NG.npy'))\n",
    "print(x_data_OK.shape, y_data_OK.shape, x_data_NG.shape, y_data_NG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d1b09-abb0-4706-834a-bf37a225ad76",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c964cf9e-7aca-4bd6-9e90-19ed17969839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 47) (189, 47) (189, 47)\n",
      "(33, 47) (11, 47) (11, 47)\n",
      "(603, 47) (200, 47) (200, 47)\n",
      "(570, 2) (189, 2) (189, 2)\n",
      "(33, 2) (11, 2) (11, 2)\n",
      "(603, 2) (200, 2) (200, 2)\n",
      "--- 0.004984378814697266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x_train_OK, x_val_test_OK, y_train_OK, y_val_test_OK = train_test_split(x_data_OK, y_data_OK, test_size=0.398, shuffle=False)\n",
    "x_train_NG, x_val_test_NG, y_train_NG, y_val_test_NG = train_test_split(x_data_NG, y_data_NG, test_size=0.4, shuffle=False)\n",
    "x_val_OK, x_test_OK, y_val_OK, y_test_OK = train_test_split(x_val_test_OK, y_val_test_OK, test_size=0.5, shuffle=False)\n",
    "x_val_NG, x_test_NG, y_val_NG, y_test_NG = train_test_split(x_val_test_NG, y_val_test_NG, test_size=0.5, shuffle=False)\n",
    "\n",
    "x_train = np.concatenate([x_train_OK, x_train_NG], axis=0)\n",
    "y_train = np.concatenate([y_train_OK, y_train_NG], axis=0)\n",
    "x_val = np.concatenate([x_val_OK, x_val_NG], axis=0)\n",
    "y_val = np.concatenate([y_val_OK, y_val_NG], axis=0)\n",
    "x_test = np.concatenate([x_test_OK, x_test_NG], axis=0)\n",
    "y_test = np.concatenate([y_test_OK, y_test_NG], axis=0)\n",
    "\n",
    "print(x_train_OK.shape, x_val_OK.shape, x_test_OK.shape)\n",
    "print(x_train_NG.shape, x_val_NG.shape, x_test_NG.shape)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)\n",
    "\n",
    "print(y_train_OK.shape, y_val_OK.shape, y_test_OK.shape)\n",
    "print(y_train_NG.shape, y_val_NG.shape, y_test_NG.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "print(\"--- %s seconds ---\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4b33fa-a600-4e4b-99fb-f8d59cb17ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([603, 47]) torch.Size([200, 47]) torch.Size([200, 47])\n",
      "torch.Size([603, 2]) torch.Size([200, 2]) torch.Size([200, 2])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(x_train).type(torch.float)\n",
    "y_train = torch.tensor(y_train).type(torch.float )\n",
    "x_val = torch.tensor(x_val).type(torch.float)\n",
    "y_val = torch.tensor(y_val).type(torch.float )\n",
    "x_test = torch.tensor(x_test).type(torch.float)\n",
    "y_test = torch.tensor(y_test).type(torch.float )\n",
    "\n",
    "y_train = y_train.view(-1, 2)\n",
    "y_val = y_val.view(-1, 2)\n",
    "y_test = y_test.view(-1, 2)\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b16c69c-d854-4efa-8733-f80bcdf62385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "val_ds = TensorDataset(x_val, y_val)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(val_ds[0][0].shape, val_ds[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1dfaaa1-1859-4403-98aa-6a35203a8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefectInspector0(torch.nn.Module):\n",
    "    def __init__(self,                            \n",
    "                 in_size: int = 47,\n",
    "                 out_size: int = 2,                                 \n",
    "                 dropout: float = 0.1\n",
    "                ):\n",
    "        super(DefectInspector0, self).__init__()\n",
    "\n",
    "        self.name = 'DefectInspector0'        \n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(in_size, 200)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(200)\n",
    "        self.relu1 = torch.nn.ReLU(inplace=False)\n",
    "        self.dropout1 = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.linear2 = torch.nn.Linear(200, 200)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(200)\n",
    "        self.relu2 = torch.nn.ReLU(inplace=False)\n",
    "        self.dropout1 = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.linear3 = torch.nn.Linear(200, 200)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(200)\n",
    "        self.relu3 = torch.nn.ReLU(inplace=False)\n",
    "        self.dropout1 = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.final_linear = torch.nn.Linear(200, out_size, bias=True)  \n",
    "\n",
    "    def forward(self, src: torch.Tensor): # src : (B, S, F)   \n",
    "        \n",
    "        out = self.linear1(src)       # (B, S, emb_size)      \n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.linear2(out)       # (B, S, emb_size)      \n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.linear3(out)       # (B, S, emb_size)      \n",
    "        out = self.bn3(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.final_linear(out)       # (B, S, emb_size)      \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40be2f48-fcce-4bcb-b15c-7701668a4d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no models.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = DefectInspector0(in_size=x_val.shape[1],\n",
    "                         out_size=y_val.shape[1])\n",
    "\n",
    "existing_model_path = None\n",
    "checkpoint = None\n",
    "\n",
    "load_model = True\n",
    "if load_model:\n",
    "    try:\n",
    "        #model = torch.load(os.path.join(model_save_dir, 'saved_model-10.pk'))\n",
    "        checkpoint = torch.load(existing_model_path) \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(\"The model has been loaded.\")\n",
    "         \n",
    "    except:\n",
    "        print(\"There are no models.\")\n",
    "        load_model = False\n",
    "    \n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model, device_ids=[0,1])\n",
    "model.to(device)\n",
    "\n",
    "print(\"-\"*50)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f450119-5194-47e2-bfe8-1da5a4f053f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder already exists.\n"
     ]
    }
   ],
   "source": [
    "model_save_dir = f\"./{dataset_name}_{model.name}\"\n",
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "    print('\"%s\" has been created.'%(model_save_dir))\n",
    "else:\n",
    "    print(\"The folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f41997-c6c2-46c0-bdc9-82ce717997a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2.2333523658538655e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:971: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, betas=(0.9, 0.98), eps=1e-09)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)                    \n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.000001, last_epoch=-1, verbose=False)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(epochs/1), T_mult=1, eta_min=0.000001, last_epoch=-1, verbose=False)\n",
    "# scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=400, T_mult=1, eta_max=0.0001, T_up=50, gamma=1.0)\n",
    "# optimizer = transformers.AdamW(model.parameters(), lr=0.005)\n",
    "# scheduler = transformers.get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=epochs, num_cycles=1, last_epoch=-1)\n",
    "\n",
    "epoch_li = []\n",
    "lr_li = []\n",
    "last_epoch = 10\n",
    "for epoch in range(1, last_epoch+1):\n",
    "    lr = scheduler.get_lr()[0]    \n",
    "    epoch_li.append(epoch)\n",
    "    lr_li.append(lr)\n",
    "    scheduler.step(epoch)        \n",
    "#     print(epoch, lr)\n",
    "for epoch in range(last_epoch+1, epochs+1):\n",
    "    \n",
    "    lr = scheduler.get_lr()[0]        \n",
    "    epoch_li.append(epoch)\n",
    "    lr_li.append(lr)\n",
    "\n",
    "    scheduler.step(epoch)        \n",
    "    if epoch%100==0 :\n",
    "        print(epoch, lr)\n",
    "\n",
    "# plt.title(\"Learning rate\", fontsize=18) \n",
    "plt.plot( epoch_li, lr_li, label='Learning rate')\n",
    "plt.xlabel( \"Epoch\", fontsize=14)\n",
    "plt.ylabel( \"Learning rate\", fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig( os.path.join(model_save_dir, 'learning-rate.jpg') , dpi=199) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21c9af83-c422-4686-bdd3-d95db018bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader): \n",
    "    loss_sum = 0    \n",
    "    criterion = nn.BCELoss()# nn.CrossEntropyLoss() #nn.MSELoss()\n",
    "    nIter = 0\n",
    "    with torch.no_grad(): \n",
    "        model.eval()   \n",
    "        for i, data in enumerate(data_loader):\n",
    "            output = model(data[0].to(device))            \n",
    "            loss = criterion(F.softmax(output, dim=1), data[1].to(device))\n",
    "            loss_sum += loss   \n",
    "            nIter+=1            \n",
    "    model.train()\n",
    "    return loss_sum.item()/nIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6cb5440-c148-4014-a3c0-9024bb493624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, optimizer, scheduler ):\n",
    "    print(\"Learning start...\")\n",
    "    train_start = time.time()\n",
    "        \n",
    "    criterion = nn.BCELoss()#nn.CrossEntropyLoss()#nn.MSELoss()\n",
    "        \n",
    "    epoch_start = 1    \n",
    "    train_loss_li = []\n",
    "    val_loss_li = []    \n",
    "    time_taken = 0.0    \n",
    "    best_train_losses = np.ones(10)*float('inf')\n",
    "    best_val_losses = np.ones(10)*float('inf')\n",
    "            \n",
    "    if load_model:\n",
    "        #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch_start = checkpoint['epoch']+1             \n",
    "        train_loss_li = checkpoint['train_loss_li']\n",
    "        val_loss_li = checkpoint['val_loss_li']\n",
    "        best_train_losses = np.sort(np.array(train_loss_li))[:10]\n",
    "        best_val_losses = np.sort(np.array(val_loss_li))[:10]\n",
    "        time_taken = checkpoint['time']\n",
    "        print('start epoch : %d'%(epoch_start))\n",
    "        print('best train loss : %f'%(best_train_losses.min()))\n",
    "        print('best val loss : %f'%(best_val_losses.min()))\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    for epoch in range(1, epoch_start):\n",
    "        lr = scheduler.get_lr()[0]            \n",
    "        scheduler.step(epoch)   \n",
    "\n",
    "    patience_iter = 0\n",
    "    #sigmoid = nn.Sigmoid()\n",
    "    for epoch in range(epoch_start, epochs+1):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch %d start.-------------------------------------------\"%(epoch))\n",
    "        \n",
    "        #best_model_weights = copy.deepcopy(model.state_dict())\n",
    "        #best_accuracy = 0.0        \n",
    "        \n",
    "        nIter = 0\n",
    "        train_loss = 0\n",
    "        model.train()         \n",
    "        \n",
    "        for i, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "            # print(inputs.size())\n",
    "            # print(targets.type())\n",
    "\n",
    "            optimizer.zero_grad()                        \n",
    "            output = model(inputs.to(device))   \n",
    "#             print(F.softmax(output))            \n",
    "            loss = criterion(F.softmax(output, dim=1), targets.to(device))\n",
    "            \n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()        \n",
    "            train_loss += loss\n",
    "            nIter+=1\n",
    "\n",
    "        train_loss = train_loss.item()/nIter\n",
    "        val_loss = evaluate(model, val_loader)\n",
    "                \n",
    "        train_loss_li.append(train_loss)            \n",
    "        val_loss_li.append(val_loss)\n",
    "        \n",
    "#         train_best1 = best_train_losses.min()\n",
    "#         train_best10 = best_train_losses.max()\n",
    "        val_best1 = best_val_losses.min()\n",
    "        val_best10 = best_val_losses.max()\n",
    "        \n",
    "#         if ( epoch % print_every==0  ) :    \n",
    "        if val_loss<val_best10 or (epoch==epochs) or (epoch%50==0): \n",
    "            model_to_be_saved = model\n",
    "            if torch.cuda.device_count() > 1:     \n",
    "                model_to_be_saved = model.module  \n",
    "\n",
    "            save_param_path = os.path.join(model_save_dir, \"params-\" + str(epoch) + '.pk')                  \n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model_to_be_saved.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),                        \n",
    "                    'train_loss_li': train_loss_li, \n",
    "                    'val_loss_li' : val_loss_li,\n",
    "                    'time' : (time_taken + time.time() - train_start)\n",
    "                    }, save_param_path)\n",
    "            #save_model_path = os.path.join(model_save_dir, \"model-\" + str(epoch) + '.pk')  \n",
    "            #torch.save(model_to_be_saved, save_model_path)                                          \n",
    "            \n",
    "            if (val_loss <= val_best10) :\n",
    "                best_val_losses[np.argmax(best_val_losses)] = val_loss\n",
    "\n",
    "            if (val_loss <= val_best1) :\n",
    "                patience_iter=0\n",
    "                print( \"The best val loss improved from %f to %f\"%(val_best1, val_loss))\n",
    "            else:\n",
    "                patience_iter+=1\n",
    "\n",
    "        else:\n",
    "            patience_iter+=1\n",
    "            print(\"val_loss did not improve from %f\"%(best_val_losses.min()))\n",
    "        \n",
    "        if patience_iter>=patience:\n",
    "            break\n",
    "        \n",
    "        print(\"=> mse : %f | val_loss : %f | lr : %e -  %fs\"%( train_loss, val_loss, scheduler.get_lr()[0], (time.time() - epoch_start)))\n",
    "        print(\"=> Time spent : %fs\"%( time_taken + time.time() - train_start ) )\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(epoch)\n",
    "        \n",
    "        if (epoch % 10==0):\n",
    "            display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f9245a-ac1e-4fe5-948f-1497c84f59c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print(train_ds[0][0].shape, train_ds[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea183613-ccc0-42b7-a8a8-fdf2b03b3444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 357.0703125 seconds ---\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train(train_loader, val_loader, optimizer, scheduler)\n",
    "print(\"--- %s seconds ---\"%(time.time()-start_time))\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f1fbbe1-90a3-43fb-8b10-dfeadb6138ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(test_ds[0][0].shape, test_ds[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ec112e7-95a6-4790-9eb6-b5d0dc6df799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader): \n",
    "    loss_sum = 0    \n",
    "    criterion = nn.BCELoss()# nn.CrossEntropyLoss() #nn.MSELoss()\n",
    "    nIter = 0\n",
    "    nSuccess = 0\n",
    "    with torch.no_grad(): \n",
    "        model.eval()   \n",
    "        for i, data in enumerate(data_loader):\n",
    "            output = model(data[0].to(device))     \n",
    "            out = F.softmax(output, dim=1)            \n",
    "            out_max, out_indices = torch.max(out.cpu(), dim=1)            \n",
    "            target_max, target_indices = torch.max(data[1], dim=1)\n",
    "#             print((out_indices!=target_indices))\n",
    "#             print((out_indices!=target_indices).sum())\n",
    "            nSuccess += (out_indices==target_indices).sum()\n",
    "            loss = criterion(out, data[1].to(device))\n",
    "            loss_sum += loss   \n",
    "            nIter+=1                \n",
    "    return nSuccess, loss_sum.item()/nIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c8debb4-27b5-4c5c-8b89-90d1375da1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(188)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nSuccess, loss = test(model, test_loader)\n",
    "nSuccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57289e90-ef9b-4abb-8d13-8d8a13b58a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.00 %\n"
     ]
    }
   ],
   "source": [
    "print( f\"%.2f %%\"%(nSuccess/x_test.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a5b44-f03d-4f10-ac1b-b5eab161bb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23f430-2219-48b8-a37b-cd98c7ab2539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
